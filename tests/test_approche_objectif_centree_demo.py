"""
Script de test DÃ‰MO pour valider l'approche "objectif-centrÃ©e" 
Version avec simulation pour prÃ©senter les fonctionnalitÃ©s sans dÃ©pendre de l'API
"""

import sys
import os
import json
import time
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, List, Optional, Any

# Chargement explicite des variables d'environnement
from dotenv import load_dotenv
load_dotenv()

@dataclass
class MockResponse:
    """RÃ©ponse simulÃ©e de l'agent IA"""
    content: str
    execution_time: float
    tool_calls_made: List[str]

class MockAgent:
    """Agent IA simulÃ© pour dÃ©monstration"""
    
    def __init__(self):
        self.user_metrics = {
            "user_id": 1,
            "total_activities": 15,
            "avg_distance_km": 8.5,
            "avg_duration_min": 42.3,
            "avg_heart_rate": 155,
            "avg_speed_kmh": 12.1,
            "total_distance_km": 127.5,
            "last_activity_date": "2024-08-20"
        }
    
    def simulate_scenario_a_response(self) -> MockResponse:
        """Simulation rÃ©ponse pour scÃ©nario A (avec target_time)"""
        response = """
### Plan d'entraÃ®nement personnalisÃ© - Objectif 10k en 45:00

**Analyse de votre profil :**
BasÃ© sur vos 15 activitÃ©s rÃ©centes (vitesse moyenne : 12.1 km/h = 49:35 au 10k), 
votre objectif de 45:00 reprÃ©sente une amÃ©lioration de 9.3% de votre vitesse. 
Cette progression nÃ©cessite un plan structurÃ© de 8 semaines minimum.

**DurÃ©e dÃ©terminÃ©e automatiquement : 8 semaines**
**Justification :** L'Ã©cart entre votre temps actuel (â‰ˆ49:35) et l'objectif (45:00) 
nÃ©cessite une amÃ©lioration graduelle de la VMA et de l'endurance spÃ©cifique. 
8 semaines permettent une progression de 1.5% par semaine, soit un objectif rÃ©aliste et durable.

## Semaine 1 - Phase d'adaptation
| Jour | Type SÃ©ance | DurÃ©e | Description | IntensitÃ© |
|------|-------------|-------|-------------|-----------|
| Lundi | Repos | - | RÃ©cupÃ©ration complÃ¨te | Repos |
| Mardi | Endurance | 40min | Footing lÃ©ger en aisance respiratoire | Faible |
| Mercredi | FractionnÃ© | 50min | 2x(6x30/30) Ã  95% VMA + Ã©chauffement | Ã‰levÃ©e |
| Jeudi | Repos | - | Ã‰tirements ou rÃ©cupÃ©ration active | Repos |
| Vendredi | Seuil | 45min | 3x6min Ã  85% FCM + Ã©chauffement | ModÃ©rÃ©e |
| Samedi | Repos | - | PrÃ©paration sortie longue | Repos |
| Dimanche | Sortie longue | 60min | Endurance fondamentale continue | Faible |

## Semaine 2 - Progression volume
| Jour | Type SÃ©ance | DurÃ©e | Description | IntensitÃ© |
|------|-------------|-------|-------------|-----------|
| Lundi | Repos | - | RÃ©cupÃ©ration complÃ¨te | Repos |
| Mardi | Endurance | 45min | Footing lÃ©ger en aisance respiratoire | Faible |
| Mercredi | FractionnÃ© | 55min | 2x(8x30/30) Ã  95-100% VMA | Ã‰levÃ©e |
| Jeudi | Repos | - | Ã‰tirements ou rÃ©cupÃ©ration active | Repos |
| Vendredi | Seuil | 50min | 4x6min Ã  85-90% FCM | ModÃ©rÃ©e |
| Samedi | Repos | - | PrÃ©paration sortie longue | Repos |
| Dimanche | Sortie longue | 70min | Endurance fondamentale continue | Faible |

## Semaine 3-6 - Phase d'intensification
[Progression continue avec augmentation graduelle du volume et de l'intensitÃ©]

## Semaine 7 - PrÃ©-compÃ©tition
[Maintien de l'intensitÃ©, rÃ©duction du volume]

## Semaine 8 - AffÃ»tage
[Volume rÃ©duit, intensitÃ© spÃ©cifique, prÃ©paration finale]

**Objectif estimÃ© Ã  8 semaines :**
Courir 10 km en 45:00 grÃ¢ce Ã  l'amÃ©lioration de votre VMA de 13.3 km/h actuelle Ã  14.5 km/h.

**Conseils personnalisÃ©s :**
- Votre rythme cardiaque moyen (155 bpm) indique une bonne condition de base
- Augmentez progressivement la vitesse des sÃ©ances seuil de 12.1 Ã  13.3 km/h
- Travaillez la rÃ©gularitÃ© : vos 8.5km moyens par sortie sont parfaits pour le 10k

**âš ï¸ Recommandations importantes :**
- Ã‰coutez votre corps et adaptez l'intensitÃ© si nÃ©cessaire
- Hydratez-vous rÃ©guliÃ¨rement pendant les sÃ©ances
- En cas de douleur, consultez un professionnel de santÃ©
"""
        
        return MockResponse(
            content=response.strip(),
            execution_time=2.3,
            tool_calls_made=["get_user_metrics_from_db", "get_training_knowledge"]
        )
    
    def simulate_scenario_b_response(self) -> MockResponse:
        """Simulation rÃ©ponse pour scÃ©nario B (sans target_time)"""
        response = """
### Plan d'entraÃ®nement personnalisÃ© - AmÃ©lioration gÃ©nÃ©rale 10k

**Analyse de votre profil :**
Avec 15 activitÃ©s rÃ©centes et une vitesse moyenne de 12.1 km/h, vous avez un profil 
d'intermÃ©diaire rÃ©gulier. Votre potentiel d'amÃ©lioration est Ã©valuÃ© Ã  15-20% sur 10-12 semaines.

**DurÃ©e dÃ©terminÃ©e automatiquement : 10 semaines**
**Justification :** Sans objectif de temps spÃ©cifique, un plan de 10 semaines permet 
d'optimiser toutes vos filiÃ¨res Ã©nergÃ©tiques et d'explorer votre potentiel maximal 
en toute sÃ©curitÃ©.

**Objectif proposÃ© basÃ© sur vos donnÃ©es :**
Passer de votre temps actuel estimÃ© (â‰ˆ49:30) Ã  un objectif de 46:00, soit une amÃ©lioration 
de 7% rÃ©aliste sur cette durÃ©e.

## Semaine 1-2 - Ã‰valuation et adaptation
| Jour | Type SÃ©ance | DurÃ©e | Description | IntensitÃ© |
|------|-------------|-------|-------------|-----------|
| Lundi | Repos | - | RÃ©cupÃ©ration complÃ¨te | Repos |
| Mardi | Endurance | 40min | Footing d'Ã©valuation du rythme naturel | Faible |
| Mercredi | Test VMA | 50min | Test progressif + Ã©valuation FCM | Test |
| Jeudi | Repos | - | Analyse des donnÃ©es du test | Repos |
| Vendredi | Endurance | 45min | Footing Ã  l'allure dÃ©couverte | Faible |
| Samedi | Repos | - | PrÃ©paration | Repos |
| Dimanche | Sortie longue | 60min | Endurance fondamentale | Faible |

## Semaine 3-6 - DÃ©veloppement global
[Plan progressif multi-filiÃ¨res]

## Semaine 7-8 - SpÃ©cialisation 10k
[Focus sur l'allure spÃ©cifique et la rÃ©sistance]

## Semaine 9-10 - Optimisation et test
[AffÃ»tage et Ã©valuation des progrÃ¨s]

**Objectif estimÃ© Ã  10 semaines :**
AmÃ©lioration gÃ©nÃ©rale avec potentiel de courir 10 km entre 46:00 et 47:30 selon progression.

**Conseils personnalisÃ©s :**
- Profil Ã©quilibrÃ© : explorez diffÃ©rents types d'entraÃ®nement
- Distance moyenne de 8.5km idÃ©ale pour progresser sur 10k
- RÃ©gularitÃ© excellente (15 activitÃ©s) : maintenez cette constance

**âš ï¸ Recommandations importantes :**
- Ã‰coutez votre corps et adaptez l'intensitÃ© si nÃ©cessaire  
- Ce plan sans contrainte temporelle privilÃ©gie la progression durable
- RÃ©Ã©valuez vos objectifs en semaine 5 pour affiner la suite
"""
        
        return MockResponse(
            content=response.strip(),
            execution_time=2.1,
            tool_calls_made=["get_user_metrics_from_db", "get_training_knowledge"]
        )

class TestApprocheeObjectifCentreeDemo:
    """Version dÃ©mo des tests pour l'approche objectif-centrÃ©e"""
    
    def __init__(self):
        self.results = {
            "test_timestamp": datetime.now().isoformat(),
            "mode": "DEMONSTRATION",
            "scenarios": {},
            "analysis": {},
            "recommendations": []
        }
        self.agent = MockAgent()
    
    def create_test_prompt_scenario_a(self):
        """ScÃ©nario A : Avec target_time pour objectif de temps"""
        return """
SCÃ‰NARIO A - Test avec objectif de temps spÃ©cifique

PARAMÃˆTRES D'ENTRÃ‰E :
- user_id: 1
- goal: "10k"  
- level: "intermediate"
- sessions_per_week: 3
- target_time: "45:00"
- duration_weeks: 0 (agent dÃ©termine automatiquement)

ATTENDU DE L'AGENT :
1. Analyser les donnÃ©es utilisateur existantes
2. Calculer l'Ã©cart entre performance actuelle et objectif (45:00)
3. DÃ©terminer automatiquement une durÃ©e optimale (6-10 semaines attendues)
4. Justifier le choix de durÃ©e basÃ© sur l'Ã©cart de performance
5. GÃ©nÃ©rer un plan complet sur TOUTE la durÃ©e dÃ©terminÃ©e
"""
    
    def create_test_prompt_scenario_b(self):
        """ScÃ©nario B : Sans target_time pour objectif gÃ©nÃ©ral"""
        return """
SCÃ‰NARIO B - Test sans objectif de temps spÃ©cifique

PARAMÃˆTRES D'ENTRÃ‰E :
- user_id: 1
- goal: "10k" (amÃ©lioration gÃ©nÃ©rale)
- level: "intermediate"
- sessions_per_week: 3
- target_time: "" (pas de temps cible)
- duration_weeks: 0 (agent dÃ©termine automatiquement)

ATTENDU DE L'AGENT :
1. Analyser les donnÃ©es utilisateur existantes
2. Proposer un objectif de temps rÃ©aliste basÃ© sur les performances
3. DÃ©terminer une durÃ©e optimale pour exploration du potentiel
4. Justifier le choix temporel pour dÃ©veloppement complet
5. GÃ©nÃ©rer un plan Ã©volutif sur la durÃ©e dÃ©terminÃ©e
"""
    
    def run_scenario(self, scenario_name: str, prompt: str) -> Dict[str, Any]:
        """Simulation d'exÃ©cution d'un scÃ©nario"""
        print(f"\n{'='*60}")
        print(f"ğŸ§ª EXÃ‰CUTION SIMULATION - {scenario_name}")
        print(f"{'='*60}")
        
        print(f"ğŸ“¤ Prompt simulÃ© envoyÃ© Ã  l'agent...")
        print(f"ğŸ“‹ ParamÃ¨tres : {prompt[:150]}...")
        
        # Simulation dÃ©lai rÃ©seau
        import time
        time.sleep(0.5)
        
        # Obtenir la rÃ©ponse simulÃ©e
        if scenario_name == "ScÃ©nario A":
            mock_response = self.agent.simulate_scenario_a_response()
        else:
            mock_response = self.agent.simulate_scenario_b_response()
        
        print(f"ğŸ“¥ RÃ©ponse reÃ§ue de l'agent simulÃ© ({mock_response.execution_time}s)")
        print(f"ğŸ”§ Outils utilisÃ©s : {', '.join(mock_response.tool_calls_made)}")
        
        scenario_result = {
            "prompt": prompt,
            "response": mock_response.content,
            "execution_time": mock_response.execution_time,
            "tool_calls_made": mock_response.tool_calls_made,
            "errors": [],
            "retries": 0
        }
        
        print(f"âœ… ScÃ©nario {scenario_name} simulÃ© avec succÃ¨s")
        return scenario_result
    
    def analyze_response(self, scenario_name: str, response: str) -> Dict[str, Any]:
        """Analyse dÃ©taillÃ©e de la rÃ©ponse"""
        analysis = {
            "duration_determined": False,
            "duration_weeks": 0, 
            "duration_justified": False,
            "performance_gap_analyzed": False,
            "complete_plan_generated": False,
            "week_count": 0,
            "target_time_considered": False,
            "objective_proposed": False,
            "recommendations_quality": "unknown"
        }
        
        response_lower = response.lower()
        
        # 1. VÃ©rification durÃ©e dÃ©terminÃ©e
        if "durÃ©e dÃ©terminÃ©e automatiquement" in response_lower or "semaines" in response_lower:
            analysis["duration_determined"] = True
        
        # 2. Extraction nombre de semaines  
        import re
        week_patterns = [r'(\d+)\s*semaines?', r'plan de\s*(\d+)', r'durÃ©e.*?(\d+)']
        week_numbers = []
        for pattern in week_patterns:
            matches = re.findall(pattern, response_lower)
            week_numbers.extend([int(m) for m in matches])
        
        if week_numbers:
            analysis["duration_weeks"] = max(week_numbers)
            analysis["week_count"] = len([w for w in week_numbers if w <= 20])  # Semaines rÃ©alistes
        
        # 3. Justification prÃ©sente
        justification_keywords = ["justification", "parce que", "nÃ©cessite", "permet", "Ã©cart"]
        analysis["duration_justified"] = any(kw in response_lower for kw in justification_keywords)
        
        # 4. Analyse Ã©cart performance
        gap_keywords = ["Ã©cart", "amÃ©lioration", "progression", "actuel", "objectif", "vitesse"]
        analysis["performance_gap_analyzed"] = any(kw in response_lower for kw in gap_keywords)
        
        # 5. Plan complet avec tableaux
        plan_indicators = ["semaine 1", "semaine 2", "tableau", "jour", "sÃ©ance"]
        analysis["complete_plan_generated"] = any(ind in response_lower for ind in plan_indicators)
        
        # 6. Temps cible considÃ©rÃ© (pour scÃ©nario A)
        time_indicators = ["45:00", "45 min", "temps", "objectif"]
        analysis["target_time_considered"] = any(ind in response_lower for ind in time_indicators)
        
        # 7. Objectif proposÃ© (pour scÃ©nario B)
        proposal_indicators = ["objectif proposÃ©", "potentiel", "46:00", "47:30"]
        analysis["objective_proposed"] = any(ind in response_lower for ind in proposal_indicators)
        
        # 8. QualitÃ© globale
        score = 0
        if analysis["duration_determined"]: score += 2
        if analysis["duration_weeks"] >= 6: score += 2
        if analysis["duration_justified"]: score += 2
        if analysis["performance_gap_analyzed"]: score += 2
        if analysis["complete_plan_generated"]: score += 2
        
        if score >= 8: analysis["recommendations_quality"] = "excellent"
        elif score >= 6: analysis["recommendations_quality"] = "good" 
        elif score >= 4: analysis["recommendations_quality"] = "basic"
        else: analysis["recommendations_quality"] = "poor"
        
        return analysis
    
    def generate_recommendations(self) -> List[str]:
        """GÃ©nÃ©ration des recommandations d'amÃ©lioration"""
        recommendations = []
        
        scenario_a = self.results["scenarios"].get("ScÃ©nario A", {})
        scenario_b = self.results["scenarios"].get("ScÃ©nario B", {})
        
        analysis_a = scenario_a.get("analysis", {})
        analysis_b = scenario_b.get("analysis", {})
        
        # Ã‰valuation durÃ©e
        duration_a = analysis_a.get("duration_weeks", 0)
        duration_b = analysis_b.get("duration_weeks", 0)
        
        if duration_a >= 8 and duration_b >= 8:
            recommendations.append(
                "ğŸŸ¢ EXCELLENT: L'agent gÃ©nÃ¨re des plans de durÃ©e appropriÃ©e "
                f"(ScÃ©nario A: {duration_a}sem, ScÃ©nario B: {duration_b}sem). "
                "Cette approche permet une progression graduelle et durable."
            )
        elif duration_a >= 6 or duration_b >= 6:
            recommendations.append(
                "ğŸŸ¡ BIEN: L'agent gÃ©nÃ¨re des plans de durÃ©e acceptable, "
                "mais pourrait bÃ©nÃ©ficier d'optimisations pour certains objectifs."
            )
        else:
            recommendations.append(
                "ğŸ”´ CRITIQUE: Plans trop courts dÃ©tectÃ©s. "
                "Modifier les prompts pour encourager des plans de 6+ semaines minimum."
            )
        
        # Ã‰valuation justification
        if analysis_a.get("duration_justified") and analysis_b.get("duration_justified"):
            recommendations.append(
                "ğŸŸ¢ EXCELLENT: L'agent justifie systÃ©matiquement ses choix de durÃ©e "
                "en analysant les donnÃ©es utilisateur et les objectifs."
            )
        else:
            recommendations.append(
                "ğŸŸ¡ AMÃ‰LIORATION: Renforcer les consignes pour que l'agent "
                "justifie toujours ses dÃ©cisions temporelles."
            )
        
        # Ã‰valuation diffÃ©renciation scÃ©narios
        if (analysis_a.get("target_time_considered") and 
            analysis_b.get("objective_proposed")):
            recommendations.append(
                "ğŸŸ¢ EXCELLENT: L'agent adapte intelligemment sa rÃ©ponse selon "
                "la prÃ©sence ou l'absence d'un objectif de temps spÃ©cifique."
            )
        
        # Recommandations techniques
        if analysis_a.get("complete_plan_generated"):
            recommendations.append(
                "ğŸŸ¢ POSITIF: L'agent gÃ©nÃ¨re des plans dÃ©taillÃ©s avec tableaux "
                "structurÃ©s facilitant le suivi utilisateur."
            )
        
        if analysis_a.get("performance_gap_analyzed"):
            recommendations.append(
                "ğŸŸ¢ POSITIF: L'analyse de l'Ã©cart performance actuelle/objectif "
                "permet un calibrage prÃ©cis de la durÃ©e nÃ©cessaire."
            )
        
        # Recommandation globale
        quality_a = analysis_a.get("recommendations_quality", "unknown")
        quality_b = analysis_b.get("recommendations_quality", "unknown") 
        
        if quality_a == "excellent" and quality_b == "excellent":
            recommendations.append(
                "ğŸ¯ CONCLUSION: L'approche 'objectif-centrÃ©e' fonctionne parfaitement. "
                "L'agent dÃ©termine automatiquement des durÃ©es optimales et justifiÃ©es."
            )
        elif quality_a == "good" or quality_b == "good":
            recommendations.append(
                "ğŸ¯ CONCLUSION: L'approche 'objectif-centrÃ©e' est prometteuse mais "
                "nÃ©cessite des ajustements mineurs dans les prompts systÃ¨me."
            )
        else:
            recommendations.append(
                "ğŸ¯ CONCLUSION: L'approche nÃ©cessite des amÃ©liorations significatives "
                "avant dÃ©ploiement en production."
            )
        
        return recommendations
    
    def run_all_tests(self) -> Dict[str, Any]:
        """ExÃ©cution complÃ¨te des tests dÃ©mo"""
        print("ğŸš€ DÃ‰BUT DES TESTS DÃ‰MO - Approche objectif-centrÃ©e")
        print("="*70)
        print("â„¹ï¸  MODE DÃ‰MONSTRATION : Simulation des appels IA pour prÃ©sentation")
        
        # ScÃ©nario A
        prompt_a = self.create_test_prompt_scenario_a()
        result_a = self.run_scenario("ScÃ©nario A", prompt_a)
        result_a["analysis"] = self.analyze_response("ScÃ©nario A", result_a["response"])
        self.results["scenarios"]["ScÃ©nario A"] = result_a
        
        # ScÃ©nario B
        prompt_b = self.create_test_prompt_scenario_b() 
        result_b = self.run_scenario("ScÃ©nario B", prompt_b)
        result_b["analysis"] = self.analyze_response("ScÃ©nario B", result_b["response"])
        self.results["scenarios"]["ScÃ©nario B"] = result_b
        
        # Recommandations
        self.results["recommendations"] = self.generate_recommendations()
        
        return self.results
    
    def save_results(self, filename: str = "rapport_demo_approche_objectif_centree.json") -> Path:
        """Sauvegarde du rapport dÃ©mo"""
        filepath = Path(__file__).parent / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“„ Rapport dÃ©mo sauvegardÃ© : {filepath}")
        return filepath

def print_detailed_report(results: Dict[str, Any]) -> None:
    """Affichage du rapport dÃ©taillÃ©"""
    print("\n" + "="*80)
    print("ğŸ“‹ RAPPORT DÃ‰TAILLÃ‰ - Tests dÃ©mo approche objectif-centrÃ©e")
    print("="*80)
    
    print(f"\nğŸ• Timestamp : {results['test_timestamp']}")
    print(f"ğŸ­ Mode : {results['mode']}")
    
    for scenario_name, scenario_data in results["scenarios"].items():
        print(f"\n{'ğŸ”µ' if scenario_name == 'ScÃ©nario A' else 'ğŸŸ¡'} {scenario_name.upper()}")
        print("-" * 50)
        
        analysis = scenario_data["analysis"]
        
        print(f"â±ï¸  Temps d'exÃ©cution : {scenario_data['execution_time']:.2f}s")
        print(f"ğŸ”§ Outils utilisÃ©s : {', '.join(scenario_data['tool_calls_made'])}")
        print(f"ğŸ“ DurÃ©e dÃ©terminÃ©e : {'âœ…' if analysis['duration_determined'] else 'âŒ'}")
        print(f"ğŸ“… Semaines planifiÃ©es : {analysis['duration_weeks']}")
        print(f"ğŸ“ DurÃ©e justifiÃ©e : {'âœ…' if analysis['duration_justified'] else 'âŒ'}")
        print(f"ğŸ“Š Ã‰cart performance analysÃ© : {'âœ…' if analysis['performance_gap_analyzed'] else 'âŒ'}")
        print(f"ğŸ“‹ Plan complet gÃ©nÃ©rÃ© : {'âœ…' if analysis['complete_plan_generated'] else 'âŒ'}")
        
        if scenario_name == "ScÃ©nario A":
            print(f"ğŸ¯ Temps cible considÃ©rÃ© : {'âœ…' if analysis['target_time_considered'] else 'âŒ'}")
        else:
            print(f"ğŸ’¡ Objectif proposÃ© : {'âœ…' if analysis['objective_proposed'] else 'âŒ'}")
            
        print(f"â­ QualitÃ© globale : {analysis['recommendations_quality'].upper()}")
        
        # AperÃ§u rÃ©ponse
        response_preview = scenario_data["response"][:200].replace('\n', ' ')
        print(f"ğŸ“„ AperÃ§u rÃ©ponse : {response_preview}...")
    
    print(f"\nğŸ’¡ RECOMMANDATIONS ({len(results['recommendations'])})")
    print("-" * 50)
    for i, rec in enumerate(results["recommendations"], 1):
        print(f"{i}. {rec}")
    
    print(f"\nğŸ“Š MÃ‰TRIQUES DE VALIDATION")
    print("-" * 50)
    
    scenario_a_analysis = results["scenarios"]["ScÃ©nario A"]["analysis"]
    scenario_b_analysis = results["scenarios"]["ScÃ©nario B"]["analysis"]
    
    print(f"âœ… DurÃ©es appropriÃ©es : {scenario_a_analysis['duration_weeks']}sem / {scenario_b_analysis['duration_weeks']}sem")
    print(f"âœ… Justifications prÃ©sentes : ScÃ©nario A={scenario_a_analysis['duration_justified']} / ScÃ©nario B={scenario_b_analysis['duration_justified']}")
    print(f"âœ… Plans complets : ScÃ©nario A={scenario_a_analysis['complete_plan_generated']} / ScÃ©nario B={scenario_b_analysis['complete_plan_generated']}")
    print(f"âœ… DiffÃ©renciation scÃ©narios : {'OUI' if scenario_a_analysis['target_time_considered'] != scenario_b_analysis['objective_proposed'] else 'NON'}")
    
    print("\n" + "="*80)

def main():
    """Fonction principale de dÃ©monstration"""
    print("ğŸ­ DÃ‰MONSTRATION - Tests approche objectif-centrÃ©e")
    print("="*60)
    print("Cette dÃ©mo simule le comportement attendu de l'agent IA rÃ©el")
    print("pour valider l'approche sans dÃ©pendre d'API externes.")
    print()
    
    try:
        # Initialisation et exÃ©cution
        tester = TestApprocheeObjectifCentreeDemo()
        results = tester.run_all_tests()
        
        # Affichage rapport
        print_detailed_report(results)
        
        # Sauvegarde
        report_file = tester.save_results()
        
        # RÃ©sumÃ© final
        successful_scenarios = len([s for s in results["scenarios"].values() 
                                   if not s["response"].startswith("Ã‰CHEC")])
        total_scenarios = len(results["scenarios"])
        
        print(f"\nğŸ¯ RÃ‰SUMÃ‰ FINAL DÃ‰MO")
        print(f"ScÃ©narios testÃ©s : {total_scenarios}")
        print(f"ScÃ©narios simulÃ©s : {successful_scenarios}")
        print(f"Recommandations gÃ©nÃ©rÃ©es : {len(results['recommendations'])}")
        print(f"Rapport complet : {report_file}")
        
        print("\nğŸš€ PROCHAINES Ã‰TAPES RECOMMANDÃ‰ES :")
        print("1. Tester avec une vraie API OpenAI")
        print("2. Valider les durÃ©es gÃ©nÃ©rÃ©es sur diffÃ©rents profils utilisateurs")
        print("3. A/B tester l'ancienne vs nouvelle approche")
        print("4. Monitorer les mÃ©triques de satisfaction utilisateur")
        
        print("\nâœ¨ DÃ©monstration terminÃ©e avec succÃ¨s !")
        
    except Exception as e:
        print(f"âŒ Erreur lors de la dÃ©monstration : {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()