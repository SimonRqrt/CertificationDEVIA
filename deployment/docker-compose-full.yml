version: '3.8'

services:
  # === SERVICES PRINCIPALES ===
  
  # Service Django (Web + API)
  django:
    container_name: coach_ai_django
    build:
      context: ..
      dockerfile: deployment/django.Dockerfile
    ports:
      - "8002:8002"
    env_file:
      - ../.env
    environment:
      - DOCKER_ENV=true
    volumes:
      - ../data:/app/data
      - ../E3_model_IA/backend/django_app/logs:/app/logs
      - monitoring_logs:/var/log/django
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/admin/"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - coach_ai_network
    depends_on:
      - prometheus

  # Service FastAPI (IA)
  fastapi:
    container_name: coach_ai_fastapi
    build:
      context: ..
      dockerfile: deployment/fastapi.Dockerfile
    ports:
      - "8000:8000"
    env_file:
      - ../.env
    environment:
      - PYTHONPATH=/app:/app/E3_model_IA/backend/fastapi_app:/app/E3_model_IA/backend/django_app
    depends_on:
      - django
      - prometheus
    volumes:
      - ../data:/app/data
      - ../E3_model_IA:/app/E3_model_IA
      - ../E1_gestion_donnees:/app/E1_gestion_donnees
      - ../knowledge_base:/app/knowledge_base
      - monitoring_logs:/var/log/fastapi
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/docs"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - coach_ai_network

  # Service Streamlit (Frontend)
  streamlit:
    container_name: coach_ai_streamlit
    build:
      context: ..
      dockerfile: deployment/streamlit.Dockerfile
    ports:
      - "8501:8501"
    env_file:
      - ../.env
    environment:
      - DOCKER_ENV=true
    depends_on:
      - django
      - fastapi
    volumes:
      - monitoring_logs:/var/log/streamlit
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - coach_ai_network

  # === MONITORING STACK ===

  # Prometheus - Collecte des métriques
  prometheus:
    image: prom/prometheus:latest
    container_name: coach_ai_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ../E5_monitoring/prometheus/prometheus-docker.yml:/etc/prometheus/prometheus.yml
      - ../E5_monitoring/prometheus/rules:/etc/prometheus/rules
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - coach_ai_network

  # Grafana - Dashboards et visualisation
  grafana:
    image: grafana/grafana:latest
    container_name: coach_ai_grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ../E5_monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ../E5_monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      - prometheus
      - loki
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - coach_ai_network

  # Loki - Centralisation des logs
  loki:
    image: grafana/loki:latest
    container_name: coach_ai_loki
    ports:
      - "3100:3100"
    volumes:
      - ../E5_monitoring/loki/loki-config-fixed.yml:/etc/loki/local-config.yaml
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - coach_ai_network

  # Promtail - Agent collecte logs
  promtail:
    image: grafana/promtail:latest
    container_name: coach_ai_promtail
    volumes:
      - ../E5_monitoring/promtail/promtail-config-docker.yml:/etc/promtail/config.yml
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - monitoring_logs:/var/log/apps:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    restart: unless-stopped
    networks:
      - coach_ai_network

  # AlertManager - Gestion des alertes
  alertmanager:
    image: prom/alertmanager:latest
    container_name: coach_ai_alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ../E5_monitoring/alertmanager/alertmanager-docker-fixed.yml:/etc/alertmanager/alertmanager.yml
      - alertmanager_data:/alertmanager
    depends_on:
      - prometheus
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - coach_ai_network

  # Node Exporter - Métriques système
  node_exporter:
    image: prom/node-exporter:latest
    container_name: coach_ai_node_exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9100/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - coach_ai_network

  # === UTILITAIRES ===

  # Webhook receiver pour les alertes (optionnel)
  webhook_receiver:
    image: alpine/curl:latest
    container_name: coach_ai_webhook
    command: |
      sh -c "
        apk add --no-cache python3 py3-pip &&
        pip3 install flask &&
        python3 -c \"
        from flask import Flask, request
        import json
        app = Flask(__name__)
        @app.route('/webhook', methods=['POST'])
        def webhook():
            data = request.get_json()
            print('ALERT:', json.dumps(data, indent=2))
            return 'OK'
        @app.route('/webhook/critical', methods=['POST'])  
        def critical():
            data = request.get_json()
            print('CRITICAL ALERT:', json.dumps(data, indent=2))
            return 'OK'
        @app.route('/webhook/openai', methods=['POST'])
        def openai():
            data = request.get_json()
            print('OPENAI ALERT:', json.dumps(data, indent=2))
            return 'OK'
        app.run(host='0.0.0.0', port=5001)
        \"
      "
    ports:
      - "5001:5001"
    restart: unless-stopped
    networks:
      - coach_ai_network

volumes:
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  loki_data:
    driver: local
  alertmanager_data:
    driver: local
  monitoring_logs:
    driver: local

networks:
  coach_ai_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16