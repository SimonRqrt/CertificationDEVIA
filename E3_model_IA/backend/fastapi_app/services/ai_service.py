"""
Service IA pour la gestion des interactions avec l'agent
"""

import json
import time
import uuid
from datetime import datetime
from langchain_core.messages import HumanMessage

from django_auth_service import django_auth_service

class AIService:
    def __init__(self, coaching_agent):
        self.coaching_agent = coaching_agent
    
    async def chat_stream(self, chat_request, user_id=None):
        """Stream de chat avec l'agent IA"""
        start_time = time.time()
        session_id = str(uuid.uuid4())
        
        user_id = user_id or chat_request.user_id or 1
        full_input = f"Je suis l'utilisateur {user_id}. {chat_request.message}"
        thread_id = chat_request.thread_id or f"user-thread-{user_id}"
        
        # üîß SOLUTION FINALE: CallbackHandler int√©gr√© 
        from prometheus_callback import prometheus_callback
        config = {
            "configurable": {"thread_id": thread_id},
            "callbacks": [prometheus_callback]
        }

        # Stocker la session de coaching
        session_data = {
            'session_id': session_id,
            'title': chat_request.message[:100],
            'user_message': chat_request.message,
            'ai_response': '',
            'context_data': {'user_id': user_id},
            'response_time': None
        }

        ai_response_parts = []
        
        # D√©terminer le mode bas√© sur le thread_id
        mode = "plan_generator" if "plan-generation" in thread_id else "streamlit"
        
        async for event in self.coaching_agent.astream({
            "messages": [HumanMessage(content=full_input)], 
            "mode": mode
        }, config=config):
            for step in event.values():
                message = step["messages"][-1]
                if hasattr(message, 'content') and message.content:
                    ai_response_parts.append(message.content)
                    yield json.dumps({"type": "content", "data": message.content}) + "\n"
        
        # Finaliser la session
        end_time = time.time()
        session_data['ai_response'] = ''.join(ai_response_parts)
        session_data['response_time'] = end_time - start_time
        
        # Enregistrer dans Django
        django_auth_service.create_coaching_session(1, session_data)
        
        yield json.dumps({"type": "end", "data": "Stream finished."}) + "\n"
    
    async def chat_legacy_stream(self, chat_request):
        """Stream de chat legacy avec cl√© API"""
        user_id = chat_request.user_id or 1
        full_input = f"Je suis l'utilisateur {user_id}. {chat_request.message}"
        thread_id = chat_request.thread_id or f"user-thread-{user_id}"
        
        # Configuration standard
        config = {"configurable": {"thread_id": thread_id}}

        # D√©terminer le mode bas√© sur le thread_id
        mode = "plan_generator" if "plan-generation" in thread_id else "streamlit"
        print(f"DEBUG: thread_id={thread_id}, mode d√©tect√©={mode}")
        
        async for event in self.coaching_agent.astream({
            "messages": [HumanMessage(content=full_input)], 
            "mode": mode
        }, config=config):
            for step in event.values():
                message = step["messages"][-1]
                if hasattr(message, 'content') and message.content:
                    yield json.dumps({"type": "content", "data": message.content}) + "\n"
        yield json.dumps({"type": "end", "data": "Stream finished."}) + "\n"
    
    async def generate_training_plan(self, plan_request):
        """G√©n√©ration de plan d'entra√Ænement"""
        if not plan_request.use_advanced_agent:
            return {"error": "Agent avanc√© requis"}
        
        # Construction du prompt optimis√© - approche objectif-centr√©e
        duration_instruction = ""
        if plan_request.duration_weeks > 0:
            duration_instruction = f"- DUR√âE IMPOS√âE: {plan_request.duration_weeks} semaines exactement"
        else:
            duration_instruction = "- DUR√âE √Ä D√âTERMINER: Analyse l'√©cart entre niveau actuel et objectif pour d√©terminer la dur√©e optimale (4-20 semaines)"
        
        target_time_info = ""
        if plan_request.target_time:
            target_time_info = f"- TEMPS OBJECTIF: {plan_request.target_time} sur {plan_request.goal}"
        
        full_input = f"""Je suis l'utilisateur {plan_request.user_id}.

ANALYSE ET G√âN√àRE un plan d'entra√Ænement intelligent:
- Objectif: {plan_request.goal}  
- Niveau d√©clar√©: {plan_request.level}
- {plan_request.sessions_per_week} s√©ances/semaine
{target_time_info}
{duration_instruction}

√âTAPES OBLIGATOIRES:
1. UTILISE get_user_metrics_from_db({plan_request.user_id}) pour analyser le niveau r√©el
2. √âVALUE l'√©cart entre performance actuelle et objectif cible
3. D√âTERMINE la dur√©e optimale de pr√©paration (justifie ton choix)
4. G√âN√àRE le plan COMPLET sur cette dur√©e avec tableaux markdown pour CHAQUE semaine

IMPORTANT: Si objectif de temps donn√©, calcule une progression r√©aliste. Sinon, utilise dur√©es standards selon l'objectif.

Sois pr√©cis, r√©aliste et justifie tes choix."""

        thread_id = f"plan-generation-{plan_request.user_id}"
        
        # Configuration standard
        config = {"configurable": {"thread_id": thread_id}}
        
        print(f"G√©n√©ration plan pour user {plan_request.user_id}...")
        start_generation = time.time()
        
        # Utiliser invoke pour plus de vitesse
        result = self.coaching_agent.invoke({
            "messages": [HumanMessage(content=full_input)], 
            "mode": "plan_generator"
        }, config=config)
        
        # Extraire la r√©ponse de l'agent
        full_response = ""
        if "messages" in result and result["messages"]:
            last_message = result["messages"][-1]
            if hasattr(last_message, 'content'):
                full_response = last_message.content
        
        generation_time = time.time() - start_generation
        print(f"Plan g√©n√©r√© en {generation_time:.2f}s")
        
        if not full_response or len(full_response) < 50:
            print(f"R√©ponse trop courte: {full_response}")
            full_response = "Erreur: Plan non g√©n√©r√© correctement"
        
        return {
            "success": True,
            "plan_content": full_response,
            "user_id": plan_request.user_id,
            "goal": plan_request.goal,
            "method": "invoke_optimized",
            "generation_time_seconds": round(generation_time, 2)
        }