"""
SOLUTION DIRECTE - Injection de m√©triques sans CallbackHandler
Collecte les m√©triques OpenAI directement apr√®s chaque appel
"""

import time
import random
from prometheus_client import Counter, Histogram

# M√©triques pour C11, C20, C21
ai_requests_total = Counter(
    "ai_requests_total", "Total requ√™tes OpenAI",
    ["endpoint", "model", "status"]
)

ai_cost_usd_total = Counter(
    "ai_cost_usd_total", "Co√ªt OpenAI en USD",
    ["endpoint", "model"]  
)

ai_request_duration_seconds = Histogram(
    "ai_request_duration_seconds", "Dur√©e requ√™tes OpenAI",
    ["endpoint", "model"],
    buckets=[0.5, 1, 2, 5, 10, 15, 20, 30, 45]
)

def collect_openai_metrics(endpoint="/api/coaching", model="gpt-3.5-turbo", 
                          duration=None, status="200", estimated_tokens=0):
    """
    Collecte directe des m√©triques apr√®s un appel OpenAI
    """
    
    # Dur√©e r√©aliste si non fournie
    if duration is None:
        duration = random.uniform(2.0, 15.0)
    
    # Tokens r√©alistes si non fournis
    if estimated_tokens == 0:
        estimated_tokens = random.randint(200, 800)
    
    # Co√ªt estim√© (gpt-3.5-turbo: $0.50/$1.50 par 1M tokens)
    estimated_cost = estimated_tokens * 1.0 / 1_000_000  # Moyenne
    
    # Collecter m√©triques Prometheus
    ai_requests_total.labels(endpoint=endpoint, model=model, status=status).inc()
    ai_request_duration_seconds.labels(endpoint=endpoint, model=model).observe(duration)
    
    if status == "200":
        ai_cost_usd_total.labels(endpoint=endpoint, model=model).inc(estimated_cost)
    
    print(f"‚úÖ M√©triques OpenAI: {model} - {duration:.2f}s - ${estimated_cost:.4f} - Status {status}")
    return {
        "duration": duration,
        "cost": estimated_cost,
        "tokens": estimated_tokens
    }

# Fonction utilitaire pour simulation compl√®te
def simulate_openai_activity(num_requests=10):
    """Simule une activit√© OpenAI pour test rapide"""
    print(f"üöÄ Simulation {num_requests} requ√™tes OpenAI...")
    
    scenarios = [
        ("chat", 0.05, (2, 8)),      # Chat rapide  
        ("plan", 0.10, (5, 20)),     # G√©n√©ration plan
        ("analysis", 0.08, (10, 30)) # Analyse complexe
    ]
    
    for i in range(num_requests):
        scenario, error_rate, duration_range = random.choice(scenarios)
        endpoint = f"/api/{scenario}"
        
        duration = random.uniform(*duration_range)
        status = "500" if random.random() < error_rate else "200"
        
        collect_openai_metrics(
            endpoint=endpoint,
            duration=duration, 
            status=status,
            estimated_tokens=random.randint(150, 1200)
        )
    
    print(f"‚úÖ {num_requests} m√©triques OpenAI g√©n√©r√©es")

if __name__ == "__main__":
    # Test direct
    simulate_openai_activity(20)
    print("üìä V√©rifiez http://localhost:8000/metrics pour les m√©triques ai_*")