import sys
import os
import json
from pathlib import Path
from rich import print as rprint
from typing import Annotated, List, Any

# sys.path.append(str(Path(__file__).resolve().parent.parent))

import operator
from typing_extensions import TypedDict

from langgraph.graph import END, StateGraph
from langgraph.checkpoint.sqlite import SqliteSaver
from langchain_core.messages import HumanMessage, ToolMessage, SystemMessage, AnyMessage
from langchain_core.messages.ai import AIMessage

from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import DirectoryLoader
from langchain_core.tools import tool
from langchain_text_splitters import RecursiveCharacterTextSplitter

import sqlalchemy as sa
import sqlite3

from E1_gestion_donnees.db_manager import create_db_engine
from src.config import DATABASE_URL, OLLAMA_BASE_URL


# DÃ‰FINIT LA PERSONNALITÃ‰ ET LES RÃˆGLES DE L'AGENT
SYSTEM_PROMPT = """
Tu es un coach sportif expert, prudent et encourageant, basÃ© sur les donnÃ©es. Ton nom est "Coach AI".

Ta mission est de crÃ©er des plans d'entraÃ®nement hebdomadaires personnalisÃ©s.

**Ton processus DOIT suivre ces Ã©tapes :**
1.  **Analyse des donnÃ©es :** Commence TOUJOURS par utiliser l'outil `get_user_metrics_from_db` pour comprendre le profil de l'utilisateur.
2.  **Recherche de connaissances :** Une fois que tu as les mÃ©triques (VMA, charge, etc.), utilise l'outil `get_training_knowledge` pour rechercher les principes d'entraÃ®nement pertinents dans la base de connaissances. Pose des questions comme "principes d'entraÃ®nement pour une VMA de 14 km/h" ou "comment structurer une semaine pour un objectif 10k en 50 minutes".
3.  **MÃ©tÃ©o (Optionnel) :** Si l'utilisateur le demande, tu peux utiliser l'outil `get_weather_forecast` pour adapter une sÃ©ance (ex: remplacer une sortie longue sous la pluie par du tapis).
4.  **SynthÃ¨se et Plan :** Fais la synthÃ¨se de toutes ces informations (donnÃ©es utilisateur, connaissances expertes, mÃ©tÃ©o) pour construire une rÃ©ponse.

**Format de sortie :**
Quand tu prÃ©sentes un plan d'entraÃ®nement, utilise TOUJOURS le format Markdown suivant :

### Plan d'entraÃ®nement pour la semaine du [Date]

| Jour      | SÃ©ance                                   | IntensitÃ© | DurÃ©e EstimÃ©e | Objectifs de la sÃ©ance                       |
|-----------|------------------------------------------|-----------|---------------|----------------------------------------------|
| Lundi     | Repos                                    | -         | -             | Assimilation, prÃ©vention des blessures      |
| Mardi     | Footing lÃ©ger                            | Faible    | 45 min        | Endurance fondamentale                       |
| Mercredi  | VMA : 2x (8x 30/30) Ã  100% VMA             | Ã‰levÃ©e    | 50 min        | AmÃ©lioration de la VO2max et de la vitesse |
| Jeudi     | Repos                                    | -         | -             |                                              |
| Vendredi  | SÃ©ance de seuil : 3x8 min Ã  85-90% FCM   | ModÃ©rÃ©e   | 1h            | AmÃ©lioration de l'endurance spÃ©cifique      |
| Samedi    | Repos                                    | -         | -             |                                              |
| Dimanche  | Sortie Longue en endurance fondamentale | Faible    | 1h30          | AmÃ©lioration de la capacitÃ© aÃ©robie         |

**Important :** Sois toujours positif et prudent. Ajoute toujours une note pour rappeler Ã  l'utilisateur d'Ã©couter son corps et de consulter un mÃ©decin.
"""


# --- Initialisation des Outils et Services ---

try:
    loader = DirectoryLoader("knowledge_base/", glob="**/*.md", show_progress=True)
    documents = loader.load()
    if not documents:
        rprint("[bold red]AVERTISSEMENT : Le dossier 'knowledge_base' est vide ou introuvable. L'outil de RAG ne fonctionnera pas.[/bold red]")
        knowledge_retriever = None
    else:
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(documents)
        vectorstore = FAISS.from_documents(documents=splits, embedding=OllamaEmbeddings(model="llama3", base_url=OLLAMA_BASE_URL))
        knowledge_retriever = vectorstore.as_retriever()
        rprint("[bold green]âœ… Base de connaissances RAG initialisÃ©e avec succÃ¨s.[/bold green]")
except Exception as e:
    rprint(f"[bold red]Erreur lors de l'initialisation du RAG : {e}[/bold red]")
    knowledge_retriever = None



@tool
def dummy_weather_tool(location: str) -> str:
    """Renvoie la mÃ©tÃ©o simulÃ©e pour un lieu donnÃ©."""
    weather_data = {
        "Paris": "â˜ï¸ 12Â°C, nuageux, vent modÃ©rÃ©",
        "Lille": "ðŸŒ¤ï¸ 15Â°C, ensoleillÃ©, vent lÃ©ger",
        "Marseille": "â˜€ï¸ 20Â°C, grand soleil, pas de vent"
    }
    return weather_data.get(location, f"MÃ©tÃ©o inconnue pour {location}")

# --- Initialisation de la base de connaissances (RAG) ---
# Ceci ne devrait Ãªtre fait qu'une seule fois au dÃ©marrage de l'application
def get_training_knowledge(query: str) -> str:
    """
    Recherche dans la base de connaissances sportives des informations pertinentes
    pour rÃ©pondre Ã  une question sur les principes d'entraÃ®nement.
    Utilise-le pour trouver comment construire un plan basÃ© sur les mÃ©triques d'un utilisateur.
    """
    if knowledge_retriever is None:
        return "Erreur : La base de connaissances n'est pas disponible."
    
    docs = knowledge_retriever.invoke(query)
    return "\n\n".join([doc.page_content for doc in docs])

def get_user_metrics_from_db(user_id: int) -> str:
    """
    RÃ©cupÃ¨re les mÃ©triques de performance les plus rÃ©centes pour un utilisateur donnÃ©.
    Retourne les donnÃ©es au format JSON.
    """
    try:
        engine = create_db_engine()
        metadata = sa.MetaData()
        metrics_table = sa.Table("metrics", metadata, autoload_with=engine)
        with engine.connect() as conn:
            stmt = sa.select(metrics_table).where(metrics_table.c.user_id == user_id).order_by(sa.desc(metrics_table.c.date_calcul))
            result = conn.execute(stmt).mappings().first()

        if not result:
            return json.dumps({"error": f"Aucune mÃ©trique trouvÃ©e pour l'utilisateur {user_id}."})
    except Exception as e:
        rprint(f"[bold red]Erreur dans l'outil get_user_metrics_from_db : {e}[/bold red]")
        return json.dumps({"error": f"Erreur de base de donnÃ©es lors de la rÃ©cupÃ©ration des mÃ©triques pour l'utilisateur {user_id}."})

    return json.dumps(dict(result), default=str)


# === Enregistrement des outils ===
tools = [get_user_metrics_from_db, get_training_knowledge]

llm = ChatOllama(model="llama3", base_url=OLLAMA_BASE_URL)

# llm_with_tools = llm.bind_tools(tools)


# === Structure d'Ã©tat du graphe ===
class AgentState(TypedDict):
    messages: Annotated[list[AnyMessage], operator.add]


# === Fonctions du graphe ===
def call_llm(state: AgentState) -> AgentState:
    # CORRECTION : On utilise le vrai SYSTEM_PROMPT que nous avons dÃ©fini
    system_msg = SystemMessage(content=SYSTEM_PROMPT)
    
    full_history = [system_msg] + state["messages"]
    
    response = llm.invoke(full_history, tools=tools)

    return {"messages": [response]}


def needs_tool(state: AgentState) -> str:
    if state["messages"][-1].tool_calls:
        return "action"
    return END

def use_tool(state: AgentState) -> AgentState:
    tool_calls = state["messages"][-1].tool_calls
    results = []
    for call in tool_calls:
        tool_to_use = {t.name: t for t in tools}[call["name"]]
        rprint(f"[bold cyan]ðŸ”§ Utilisation de l'outil : {tool_to_use.name}({call['args']})[/bold cyan]")
        output = tool_to_use.invoke(call["args"])
        results.append(ToolMessage(tool_call_id=call["id"], name=call["name"], content=str(output)))
    return {"messages": results}

def get_coaching_graph():
    """
    Construit et compile le graphe LangGraph de l'agent coach.
    Retourne l'objet graphe prÃªt Ã  l'emploi.
    """

    graph_builder = StateGraph(AgentState)
    graph_builder.add_node("llm", call_llm)
    graph_builder.add_node("action", use_tool)
    graph_builder.add_conditional_edges("llm", needs_tool, {"action": "action", END: END})
    graph_builder.add_edge("action", "llm")
    graph_builder.set_entry_point("llm")

    try:
        conn = sqlite3.connect("data/agent_memory.sqlite", check_same_thread=False)
        memory = SqliteSaver(conn=conn)
    except Exception as e:
        rprint(f"[bold red]ERREUR CRITIQUE : Impossible de se connecter Ã  la BDD pour la mÃ©moire de l'agent : {e}[/bold red]")
        raise

    graph = graph_builder.compile(checkpointer=memory)
    rprint("[bold green]âœ… Graphe de coaching IA compilÃ©.[/bold green]")
    return graph


# === Boucle de test CLI amÃ©liorÃ©e ===
if __name__ == "__main__":
    rprint("[bold yellow]ðŸŽ½ Assistant sportif intelligent prÃªt ! (Tape 'quit' pour sortir)[/bold yellow]")
    
    graph = get_coaching_graph()
    CURRENT_USER_ID = 1
    rprint(f"[yellow]Utilisateur actuel : ID {CURRENT_USER_ID}[/yellow]")
  
    while True:
        user_input = input("ðŸ§  Votre question : ")
        if user_input.lower() in ("quit", "exit", "q"):
            rprint("[bold green]Ã€ bientÃ´t ![/bold green]")
            break

        full_input = f"Je suis l'utilisateur {CURRENT_USER_ID}. {user_input}"

        for event in graph.stream(
            {"messages": [HumanMessage(content=full_input)]},
            config={"configurable": {"thread_id": f"cli-thread-user-{CURRENT_USER_ID}"}}
        ):
            for step in event.values():
                message = step["messages"][-1]
                if isinstance(message, AIMessage) and message.content:
                    rprint(f"\nðŸ¤– [green]{message.content}[/green]")
